{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sort Images with Artificial Intelligence\n",
    "In this project we are going to train an AI Model which will be able to sort and understand our images. In the end we will use the AI to recognize what is shown on the picture and move the image to a proper folder.\n",
    "By using this project by yourself, you can save a lot of time by using the AI instead of going through the pictures by yourself.\n",
    "We are going to use so called Transfer Learning for this project. We take a pretrained CNN (Convolutional Neural Network), the VGG 16 and we are going to cut off the last layers where the decision takes place. The CNN is able to recognize all the Features on the image, only the Decision Making Park (Feedforward Neural Network) has to be retrained.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Step: Read the Training-Images\n",
    "First we store similar pictures in the same folder because our model has to be trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from PIL import Image\n",
    "\n",
    "def read_images(path):\n",
    "    files = os.listdir(path)\n",
    "    \n",
    "    files = [file for file in files if file[-4:] == \".jpg\" or file[-4:] == \".JPG\" or file[-4:] == \".PNG\" or file[-4:] == \".png\"]\n",
    "    images = []\n",
    "    for file in files:\n",
    "        try:\n",
    "            image = Image.open(os.path.join(path, file))\n",
    "\n",
    "            # https://pillow.readthedocs.io/en/3.1.x/reference/Image.html#PIL.Image.Image.resize\n",
    "            image = image.resize((224, 224), Image.LANCZOS)\n",
    "\n",
    "            # https://pillow.readthedocs.io/en/3.1.x/reference/Image.html#PIL.Image.Image.convert\n",
    "            image = image.convert(\"RGB\")\n",
    "\n",
    "            image = np.asarray(image)\n",
    "\n",
    "            images.append(image)\n",
    "        except OSError:\n",
    "            pass\n",
    "    \n",
    "    return images\n",
    "    \n",
    "selfie = read_images(os.path.join(\"Me\"))\n",
    "mountains = read_images(os.path.join(\"Mountains\"))\n",
    "\n",
    "selfie = np.asarray(selfie)\n",
    "mountains = np.asarray(mountains)\n",
    "\n",
    "\n",
    "X = np.concatenate([selfie, mountains])\n",
    "\n",
    "# Generate Labels for the data - we associate zero with dogs, one with selfies and two with mountains\n",
    "y_selfie = np.ones(len(selfie))\n",
    "y_mountains = np.zeros(len(mountains))\n",
    "\n",
    "y = np.concatenate([y_selfie, y_mountains])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning with VGG 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "\n",
    "# Preprocess data with existing VGG 16\n",
    "X = preprocess_input(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_model = VGG16(include_top = False, input_shape = (224,224,3))\n",
    "vgg16_model.trainable = False\n",
    "\n",
    "X_after_vgg = vgg16_model.predict(X, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 7, 7, 512)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_after_vgg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "X_after_vgg, y = shuffle(X_after_vgg, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_3 (Flatten)         (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1024)              25691136  \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 16)                16400     \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,707,553\n",
      "Trainable params: 25,707,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from tensorflow import keras\n",
    "\n",
    "# Define Optimizer\n",
    "opt = keras.optimizers.Adam(learning_rate=0.1)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Flatten(input_shape=(7, 7, 512)))\n",
    "model.add(Dense(1024, activation=\"relu\"))\n",
    "model.add(Dense(16, activation=\"relu\"))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(optimizer=opt, loss=\"binary_crossentropy\", metrics=[\"acc\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 1s 545ms/step - loss: 1.9312 - acc: 0.4167 - val_loss: 9179.8018 - val_acc: 0.6667\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 18678.2871 - acc: 0.5000 - val_loss: 1107.3019 - val_acc: 0.3333\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 831.6065 - acc: 0.6667 - val_loss: 50.8384 - val_acc: 0.6667\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 726.7048 - val_acc: 0.6667\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 8372.6592 - acc: 0.5000 - val_loss: 183.2877 - val_acc: 0.6667\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 371.2612 - val_acc: 0.6667\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 6.5684e-34 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23c614e2b20>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_after_vgg, y, epochs=10, batch_size=64, validation_split=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the trained model to disk\n",
    "model.save(\"Mountain_Selfie.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the test data\n",
    "testing = read_images(os.path.join(\"Testing\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre Process Input\n",
    "testing = np.asarray(testing)\n",
    "testing = preprocess_input(testing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 224, 224, 3)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_after_vgg_testing = vgg16_model.predict(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.6332612e-28],\n",
       "       [6.6269170e-38],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_after_vgg_testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Move Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Library os - Operating System interface\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "\n",
    "# Path to your files\n",
    "\n",
    "path_file = \"Testing\"\n",
    "\n",
    "# Lambda Function - Get all the files from a specific folder\n",
    "filenames = [f for f in listdir(path_file) if isfile(join(path_file, f)) if f[-4:] == \".jpg\" or f[-4:] == \".JPG\" or f[-4:] == \".PNG\" or f[-4:] == \".png\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_single(path):\n",
    "    try:\n",
    "        image = Image.open(os.path.join(path))\n",
    "\n",
    "        # https://pillow.readthedocs.io/en/3.1.x/reference/Image.html#PIL.Image.Image.resize\n",
    "        image = image.resize((224, 224), Image.LANCZOS)\n",
    "\n",
    "        # https://pillow.readthedocs.io/en/3.1.x/reference/Image.html#PIL.Image.Image.convert\n",
    "        image = image.convert(\"RGB\")\n",
    "\n",
    "        image = np.asarray(image)\n",
    "\n",
    "    except OSError:\n",
    "        pass\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image):\n",
    "    image = np.asarray(image)\n",
    "    image = image.reshape(-1,224, 224, 3)\n",
    "    image = preprocess_input(image)\n",
    "    X_after_vgg = vgg16_model.predict(image)\n",
    "    return model.predict(X_after_vgg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in filenames:\n",
    "    testing = read_single(os.path.join(\"Testing\", file))\n",
    "    if predict(testing) == 0:\n",
    "        os.rename( join(\"Testing\", file), join(\"Mountains\", file))\n",
    "    elif predict(testing) == 1:\n",
    "        os.rename( join(\"Testing\", file), join(\"Me\", file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
